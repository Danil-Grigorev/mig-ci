#!groovy

// Set Job properties and triggers
properties([disableConcurrentBuilds(), 
parameters([string(defaultValue: 'v3.11', description: 'OCP3 version to deploy', name: 'OPENSHIFT_VERSION', trim: false), 
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'ci_aws_access_key_id', description: 'EC2 access key ID for auth purposes', name: 'EC2_ACCESS_KEY_ID', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'ci_aws_secret_access_key', description: 'EC2 private key needed to access instances, from Jenkins credentials store', name: 'EC2_SECRET_ACCESS_KEY', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.FileCredentialsImpl', defaultValue: 'ci_ec2_key', description: 'EC2 private key needed to access instances, from Jenkins credentials store', name: 'EC2_PRIV_KEY', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'ci_rhel_sub_user', description: 'RHEL Openshift subscription account username', name: 'EC2_SUB_USER', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'ci_rhel_sub_pass', description: 'RHEL Openshift subscription account password', name: 'EC2_SUB_PASS', required: true),
string(defaultValue: 'ci', description: 'EC2 SSH key name to deploy on instances for remote access ', name: 'EC2_KEY', trim: false),
string(defaultValue: 'ci.pem', description: 'EC2 SSH private key filename to access instances', name: 'EC2_PRIVATE_KEY_FILE', trim: false),
string(defaultValue: 'eu-west-1', description: 'EC2 region to deploy instances', name: 'EC2_REGION', trim: false),
string(defaultValue: 'm4.large', description: 'EC2 instance type to deploy', name: 'EC2_INSTANCE_TYPE', trim: false),
string(defaultValue: 'jenkins-ci', description: 'OCP4 cluster name to deploy', name: 'OCP4_CLUSTER_NAME', trim: false),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.FileCredentialsImpl', defaultValue: 'ci_pull_secret', description: 'Pull secret needed for OCP4 deployments', name: 'OCP4_PULL_SECRET', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.FileCredentialsImpl', defaultValue: 'ci_pub_key', description: 'EC2 public key needed for OCP4 instances', name: 'EC2_PUB_KEY', required: true),
string(defaultValue: 'ci.pub', description: 'EC2 SSH public key filename to access instances', name: 'EC2_PUBLIC_KEY_FILE', trim: false),
string(defaultValue: 'https://github.com/Danil-Grigorev/mig-ci.git', description: 'MIG CI repo URL to checkout', name: 'MIG_CI_REPO', trim: false),
string(defaultValue: 'aws-all-in-one-migrate', description: 'MIG CI repo branch to checkout', name: 'MIG_CI_BRANCH', trim: false),
string(defaultValue: 'https://github.com/fusor/mig-e2e.git', description: 'MIG E2E repo URL to checkout', name: 'MIG_E2E_REPO', trim: false),
string(defaultValue: 'master', description: 'MIG E2E repo branch to checkout', name: 'MIG_E2E_BRANCH', trim: false),
booleanParam(defaultValue: true, description: 'Clean up workspace after build', name: 'CLEAN_WORKSPACE'),
booleanParam(defaultValue: true, description: 'EC2 terminate instances after build', name: 'EC2_TERMINATE_INSTANCES')]),
[$class: 'ThrottleJobProperty', categories: ['OCP'], limitOneJobWithMatchingParams: true, maxConcurrentPerNode: 0, maxConcurrentTotal: 0, paramsToUseForLimit: '', throttleEnabled: true, throttleOption: 'category']])

// true/false build parameter that defines if we terminate instances once build is done
def EC2_TERMINATE_INSTANCES = params.EC2_TERMINATE_INSTANCES
// true/false build parameter that defines if we cleanup workspace once build is done
def CLEAN_WORKSPACE = params.CLEAN_WORKSPACE

echo "Running job ${env.JOB_NAME}, build ${env.BUILD_ID} on ${env.JENKINS_URL}"
echo "Build URL ${env.BUILD_URL}"
echo "Job URL ${env.JOB_URL}"

node {
    try {
        notifyBuild('STARTED')   
        stage('Prepare Build Environment') {

            sh 'printenv'
            
            // Prepare EC2 key for ansible consumption
            KEYS_DIR = "${env.WORKSPACE}" + '/keys'
            sh "mkdir -p ${KEYS_DIR}"
            
            withCredentials([file(credentialsId: "$EC2_PRIV_KEY", variable: "SSH_PRIV_KEY")]) {
             
                sh "cat ${SSH_PRIV_KEY} > ${KEYS_DIR}/${EC2_PRIVATE_KEY_FILE}"
                sh "chmod 600 ${KEYS_DIR}/${EC2_PRIVATE_KEY_FILE}"
            }
            
            echo 'Cloning mig-ci repo'
            checkout([$class: 'GitSCM', branches: [[name: "*/$MIG_CI_BRANCH"]], doGenerateSubmoduleConfigurations: false, extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'mig-ci']], submoduleCfg: [], userRemoteConfigs: [[url: "$MIG_CI_REPO"]]])

            // Set enviroment variables
            EC2_REGION = "${EC2_REGION}"
            OCP4_CLUSTER_NAME = "${OCP4_CLUSTER_NAME}"
            KUBECONFIG_TMP = "${env.WORKSPACE}/tmp-kubeconfig"

            // Target kubeconfig locations
            KUBECONFIG_OCP3 = "/var/lib/jenkins/kubeconfigs/ocp3-kubeconfig"
            KUBECONFIG_OCP4 = "/var/lib/jenkins/kubeconfigs/ocp4-kubeconfig"

            sh "rm -f ${KUBECONFIG_TMP}"

            dir('mig-ci') {
                // Prepare pull secret
                withCredentials([file(credentialsId: "$OCP4_PULL_SECRET", variable: "PULL_SECRET")]) {
                    sh 'cat ${PULL_SECRET} > config/pull-secret'
                }
                
                // Prepare EC2 pub key for ansible consumption
                withCredentials([file(credentialsId: "$EC2_PUB_KEY", variable: "SSH_PUB_KEY")]) {
                    sh "cat ${SSH_PUB_KEY} > config/${EC2_PUBLIC_KEY_FILE}"
                }
            }
            
            echo 'Cloning mig-e2e repo'
            checkout([$class: 'GitSCM', branches: [[name: "*/$MIG_E2E_BRANCH"]], doGenerateSubmoduleConfigurations: false, extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'mig-e2e']], submoduleCfg: [], userRemoteConfigs: [[url: "$MIG_E2E_REPO"]]])

            echo 'Cloning ocp-mig-test-data repo'
            checkout([$class: 'GitSCM', branches: [[name: '*/master']], doGenerateSubmoduleConfigurations: false, extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'ocp-mig-test-data']], submoduleCfg: [], userRemoteConfigs: [[url: 'https://github.com/fusor/ocp-mig-test-data.git']]])

        }
    
        stage('Deploy OCP3') {
            withCredentials([
                string(credentialsId: "$EC2_ACCESS_KEY_ID", variable: 'AWS_ACCESS_KEY_ID'),
                string(credentialsId: "$EC2_SECRET_ACCESS_KEY", variable: 'AWS_SECRET_ACCESS_KEY'),
                string(credentialsId: "$EC2_SUB_USER", variable: 'SUB_USER'),
                string(credentialsId: "$EC2_SUB_PASS", variable: 'SUB_PASS')
                ]) 
            {
                dir('mig-ci') {
                    withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_TMP}"]) {
                        echo "WS: $WORKSPACE, $KEYS_DIR, $EC2_PRIVATE_KEY_FILE"
                        ansiColor('xterm') {
                            ansiblePlaybook(
                                playbook: 'get_ocp3_oa.yml',
                                hostKeyChecking: false,
                                unbuffered: true,
                                colorized: true)
                        }
                        ansiColor('xterm') {
                            ansiblePlaybook(
                                playbook: 'deploy_ocp3_cluster.yml',
                                hostKeyChecking: false,
                                unbuffered: true,
                                colorized: true)
                        }
                    }
                }
            }
        }

	stage('Configure NFS storage on OCP3') {
		dir('mig-ci') {
                        ansiColor('xterm') {
                            ansiblePlaybook(
                                playbook: 'setup_nfs_storage.yml',
                                extras: "-e ec2_private_key_file=$KEYS_DIR/$EC2_PRIVATE_KEY_FILE",
                                hostKeyChecking: false,
                                unbuffered: true,
                                colorized: true)
			}
		}
	}
	
        stage('Deploy Velero and configure S3 storage on OCP3') {
            withCredentials([
                string(credentialsId: "$EC2_ACCESS_KEY_ID", variable: 'AWS_ACCESS_KEY_ID'),
                string(credentialsId: "$EC2_SECRET_ACCESS_KEY", variable: 'AWS_SECRET_ACCESS_KEY')
                ]) 
            {
                
                withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_TMP}"]) {
                    dir('mig-ci') {
                        ansiColor('xterm') {
                            ansiblePlaybook(
                                playbook: 'setup_velero.yml',
                                extras: "-e cluster_version=3",
                                hostKeyChecking: false,
                                unbuffered: true,
                                colorized: true)
                        }
                    }
                }
            }
        }

        stage('Run OCP3 Sanity Checks') {
           
            dir('mig-ci') {
                withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_TMP}"]) {
                    ansiColor('xterm') {
                        ansiblePlaybook(
                            playbook: 'ocp_sanity_check.yml',
                            tags: 'router',
                            extras: '',
                            hostKeyChecking: false,
                            unbuffered: true,
                            colorized: true)
                    }
                }
            }
	}

        stage('Deploy OCP4') {
            withCredentials([
                string(credentialsId: "$EC2_ACCESS_KEY_ID", variable: 'AWS_ACCESS_KEY_ID'),
                string(credentialsId: "$EC2_SECRET_ACCESS_KEY", variable: 'AWS_SECRET_ACCESS_KEY')
                ]) 
            {

                dir('mig-ci') {
                    withEnv(['PATH+EXTRA=~/bin']) {
                        ansiColor('xterm') {
                            ansiblePlaybook(
                                playbook: 'deploy_ocp4_cluster.yml',
                                hostKeyChecking: false,
                                unbuffered: true,
                                colorized: true)
                        }
                    }
                }
            }
        }

        stage('Deploy Velero and configure S3 storage on OCP4') {
            withCredentials([
                string(credentialsId: "$EC2_ACCESS_KEY_ID", variable: 'AWS_ACCESS_KEY_ID'),
                string(credentialsId: "$EC2_SECRET_ACCESS_KEY", variable: 'AWS_SECRET_ACCESS_KEY')
                ]) 
            {
                
                withEnv(['PATH+EXTRA=~/bin']) {
                    dir('mig-ci') {
                        ansiColor('xterm') {
                            ansiblePlaybook(
                                playbook: 'setup_velero.yml',
                                extraVars: "-vvv",
                                extras: "-e cluster_version=4",
                                hostKeyChecking: false,
                                unbuffered: true,
                                colorized: true)
                        }
                    }
                }
            }
        }

        stage('Run OCP4 sanity checks') {
            // TODO
        }

        stage('Run mig-e2e tests') {

        // placeholder for mig-e2e playbooks
            // Create msql-pvc with backup on OCP3
            withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_OCP3}"]) {
                dir('ocp-mig-test-data') {
                    ansiColor('xterm') {
                        ansiblePlaybook(
                            playbook: 'mysql-pvc.yml',
                            extras: "-e with_backup=true -e with_restore=false -e with_data=false -e with_resources=true",
                            hostKeyChecking: false,
                            unbuffered: true,
                            colorized: true)
                    }
                }
            }
            
            // Restore on OCP4
            withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_OCP4}"]) {
                dir('ocp-mig-test-data') {
                    ansiColor('xterm') {
                        ansiblePlaybook(
                            playbook: 'mysql-pvc.yml',
                            extras: "-e with_backup=false -e with_restore=true -e with_data=false -e with_resources=false",
                            hostKeyChecking: false,
                            unbuffered: true,
                            colorized: true)
                    }
                }
            }
        }
        
    } catch (e) {
        currentBuild.result = "FAILED"
        throw e
    } finally {
        // Success or failure, always send notifications
        notifyBuild(currentBuild.result)

	stage('Clean Up Environment') {
        // Always attempt to terminate instances if EC2_TERMINATE_INSTANCES is true
		if (EC2_TERMINATE_INSTANCES) {
            		withCredentials([
                		string(credentialsId: "$EC2_ACCESS_KEY_ID", variable: 'AWS_ACCESS_KEY_ID'),
                		string(credentialsId: "$EC2_SECRET_ACCESS_KEY", variable: 'AWS_SECRET_ACCESS_KEY')
                		]) 
            		{
                		withEnv(['PATH+EXTRA=~/bin']) {
                    			dir('mig-ci') {
                        			ansiColor('xterm') {
                            				ansiblePlaybook(
                                				playbook: 'destroy_ocp3_cluster.yml',
                                				hostKeyChecking: false,
                                				unbuffered: true,
                                				colorized: true)
                        			}
                        			ansiColor('xterm') {
                            				ansiblePlaybook(
                                				playbook: 'destroy_ocp4_cluster.yml',
                                				hostKeyChecking: false,
                                				unbuffered: true,
                                				colorized: true)
                        			}
                    			}
                		}
            		}
        	}
		if (CLEAN_WORKSPACE) {  
			cleanWs cleanWhenFailure: false, notFailBuild: true
		}
	}
    }
}

def notifyBuild(String buildStatus = 'STARTED') {
  // build status of null means successful
  buildStatus =  buildStatus ?: 'SUCCESSFUL'
 
  // Default values
  def colorName = 'RED'
  def colorCode = '#FF0000'
  def subject = "${buildStatus}: Job '${env.JOB_NAME}, build [${env.BUILD_NUMBER}]'"
  def summary = "${subject} (${env.BUILD_URL})"
 
  // Override default values based on build status
  if (buildStatus == 'STARTED') {
    colorCode = '#FFFF00'
  } else if (buildStatus == 'SUCCESSFUL') {
    colorCode = '#00FF00'
  } else {
    colorCode = '#FF0000'
  }
 
  // Send notifications
  slackSend (color: colorCode, message: summary)
}
